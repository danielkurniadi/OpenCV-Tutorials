{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMERA CALIBRATION TUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives \n",
    "The Goal for this tutorial will be to help you learn about camera distortions \n",
    "that are typically present in photos taken with common pinhole cameras. \n",
    "We will also learn the definition and differences between intrinsic vs extrinsic \n",
    "parameters of the camera and why they are needed in our code. \n",
    "Once these parameters are found, we can use Open CV to undistort the image. \n",
    "This is the first step towards full 3D reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today’s cheap pinhole cameras introduces a lot of distortion to images. Two major distortions are radial distortion and tangential distortion.\n",
    "\n",
    "Due to radial distortion, straight lines will appear curved. Its effect is more as we move away from the center of image. For example, one image is shown below, where two edges of a chess board are marked with red lines. But you can see that border is not a straight line and doesn’t match with the red line. All the expected straight lines are bulged out. Visit Distortion (optics) for more details.\n",
    "\n",
    "![alt text](../assets/calib_radial.jpg?raw=True \"Radial Distortion on checkerboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial Distortion\n",
    "\n",
    "This distortion is solved as follows:\n",
    "$$\n",
    "x_{corrected} = x( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6) \\\\\n",
    "y_{corrected} = y( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6)\n",
    "$$\n",
    "\n",
    "#### Tangential Distortion\n",
    "Similarly, another distortion is the tangential distortion which occurs because image taking lense is not aligned perfectly parallel to the imaging plane. So some areas in image may look nearer than expected. It is solved as below:\n",
    "\n",
    "$$\n",
    "x_{corrected} = x + [ 2p_1xy + p_2(r^2+2x^2)] \\\\\n",
    "y_{corrected} = y + [ p_1(r^2+ 2y^2)+ 2p_2xy]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distortion Coeff\n",
    "In short, we need to find five parameters, known as distortion coefficients given by:\n",
    "\n",
    "$$Distortion \\; coefficients=(k_1 \\hspace{10pt} k_2 \\hspace{10pt} p_1 \\hspace{10pt} p_2 \\hspace{10pt} k_3)$$\n",
    "\n",
    "#### Camera Matrix\n",
    "\n",
    "In addition to this, we need to find a few more information, like intrinsic and extrinsic parameters of a camera. Intrinsic parameters are specific to a camera. It includes information like focal length (f_x,f_y), optical centers (c_x, c_y) etc. It is also called camera matrix. It depends on the camera only, so once calculated, it can be stored for future purposes. It is expressed as a 3x3 matrix:\n",
    "\n",
    "$$camera \\; matrix = \\left [ \\begin{matrix}   f_x & 0 & c_x \\\\  0 & f_y & c_y \\\\   0 & 0 & 1 \\end{matrix} \\right ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Extrinsic parameters corresponds to rotation and translation vectors which translates a coordinates of a 3D point to a coordinate system.\n",
    "\n",
    "For stereo applications, these distortions need to be corrected first. To find all these parameters, what we have to do is to provide some sample images of a well defined pattern (eg, chess board). We find some specific points in it ( square corners in chess board). We know its coordinates in real world space and we know its coordinates in image. With these data, some mathematical problem is solved in background to get the distortion coefficients. That is the summary of the whole story. For better results, we need atleast 10 test patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sake of understanding, consider just one image of a chess board. Important input datas needed for camera calibration is a set of 3D real world points and its corresponding 2D image points. 2D image points are OK which we can easily find from the image. (These image points are locations where two black squares touch each other in chess boards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the 3D points from real world space? Those images are taken from a static camera and chess boards are placed at different locations and orientations. So we need to know (X,Y,Z) values. But for simplicity, we can say chess board was kept stationary at XY plane, (so Z=0 always) and camera was moved accordingly. This consideration helps us to find only X,Y values. Now for X,Y values, we can simply pass the points as (0,0), (1,0), (2,0), ... which denotes the location of points. In this case, the results we get will be in the scale of size of chess board square. But if we know the square size, (say 30 mm), and we can pass the values as (0,0),(30,0),(60,0),..., we get the results in mm. (In this case, we don’t know square size since we didn’t take those images, so we pass in terms of square size)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob # global path/file finder\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to find pattern in chess board, we use the function, **cv2.findChessboardCorners()**. We also need to pass what kind of pattern we are looking, like 8x8 grid, 5x5 grid etc. In this example, we use 7x6 grid. (Normally a chess board has 8x8 squares and 7x7 internal corners). It returns the corner points and retval which will be True if pattern is obtained. These corners will be placed in an order (from left-to-right, top-to-bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a 7 x 6 checkboard corners. It doesn't have to be this shape but for this purpose, we only take 42 points. We use `np.mgrid` to create meshgrid-like points. This object points simplify the representation of 3d point in real world space. In this case, the corners of checker board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise grid object points of shape (7 x 6)\n",
    "pshape = (7 * 6, 3)\n",
    "objp = np.zeros(pshape, np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "# array to store object points and image points for all images \n",
    "objpoints_list = []  # 3d point in real space \n",
    "imgpoints_list = []  # 2d point in image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4., 5., 6., 0., 1., 2.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objp[:10].T  # display object point representation for corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "imagepaths = glob.glob(\"data/*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Corners of Checkerboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we find the corners, we can increase their accuracy using **cv2.cornerSubPix()**. We can also draw the pattern using **cv2.drawChessboardCorners()**. All these steps are included in below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria for refining corners pix\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find chessboard corners for every image in folders './data'\n",
    "for fname in imagepaths:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # find corner of checker/chess board\n",
    "    success, corners = cv2.findChessboardCorners(img, (7,6), cv2.CALIB_CB_ADAPpythonTIVE_THRESH)\n",
    "\n",
    "    if success == True:\n",
    "        objpoints_list.append(objp)\n",
    "        \n",
    "        # refining points of found corners\n",
    "        corners2  = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints_list.append(corners)\n",
    "\n",
    "        # draw chessboard corners on image for visualisation\n",
    "        cv2.drawChessboardCorners(img, (7,6), corners2, success)\n",
    "        cv2.imshow(fname, img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/left11.jpg') # pick an image to demo calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channel = img.shape\n",
    "success, matrix, distortion, rvecs, tvecs = cv2.calibrateCamera(objpoints_list, \n",
    "    imgpoints_list, (width, height), None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undistortion\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(matrix, distortion, \n",
    "    (width,height), 1, (width,height))\n",
    "dist = cv2.undistort(img, matrix, distortion, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dist = dist[y:y+h, x:x+w]\n",
    "cv2.imwrite('artifacts/calibresult11.png', dist)\n",
    "\n",
    "cv2.imshow('calibresult', dist)\n",
    "cv2.waitKey(500); cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our results.\n",
    "We proceed to part II of this tutorial series: Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matrix, distortion coef, rotation, translation\n",
    "# with np.savez()\n",
    "outfile = \"artifacts/calibresult.npz\"\n",
    "np.savez(outfile, mtx=matrix, distr=distortion, rvecs=rvecs, tvecs=tvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner = imgpoints_list[0] # sample corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([160.0524, 306.3398], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
